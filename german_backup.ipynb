{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "german_backup.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "15ZgUTKgXw9hLKlxeZbRdr5Mo9XBvvWwH",
      "authorship_tag": "ABX9TyOJcDprT/TmUZsUVgjldiX5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satweekcr7/german-to-english-translation/blob/master/german_backup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JhOJvHjVHEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "outputId": "3fa541fb-961c-4aeb-d19d-79e3bb2e6aca"
      },
      "source": [
        "import string\n",
        "!pip install tensorflow==1.14.0\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.27.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (46.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQt6DH07nHLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2hU6e05VS08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to read raw text file\n",
        "def read_text(filename):\n",
        "        # open the file\n",
        "        file = open(filename, mode='rt', encoding='utf-8')\n",
        "        \n",
        "        # read all text\n",
        "        text = file.read()\n",
        "        file.close()\n",
        "        return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcofwXi6Vlex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split a text into sentences\n",
        "def to_lines(text):\n",
        "      sents = text.strip().split('\\n')\n",
        "      sents = [i.split('\\t') for i in sents]\n",
        "      return sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm__kK-dVz1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = read_text(\"/content/drive/My Drive/nlp/deu.txt\")\n",
        "deu_eng = to_lines(data)\n",
        "deu_eng = array(deu_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cR5S3zEWm4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove punctuation\n",
        "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
        "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QDjG0MNW6Xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert text to lowercase\n",
        "for i in range(len(deu_eng)):\n",
        "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
        "    deu_eng[i,1] = deu_eng[i,1].lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pitn5bVXW-Vk",
        "colab_type": "code",
        "outputId": "2b0f4c2e-3d63-4ae6-efc6-4b24f37eeca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# empty lists\n",
        "eng_l = []\n",
        "deu_l = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in deu_eng[:,0]:\n",
        "      eng_l.append(len(i.split()))\n",
        "\n",
        "for i in deu_eng[:,1]:\n",
        "      deu_l.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkVMELJuXGBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to build a tokenizer\n",
        "def tokenization(lines):\n",
        "      tokenizer = Tokenizer()\n",
        "      tokenizer.fit_on_texts(lines)\n",
        "      return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4whnjVSXIyP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80d56af5-4a1a-4474-a5a8-f8fb1511fc36"
      },
      "source": [
        "# prepare english tokenizer\n",
        "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "eng_length = 8\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 16380\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odGmRWb0XMf2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddc2d871-4c8b-4158-947e-14b4c7a01cc2"
      },
      "source": [
        "# prepare Deutch tokenizer\n",
        "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
        "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
        "\n",
        "deu_length = 8\n",
        "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deutch Vocabulary Size: 35442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz7cA3nkXR67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "         # integer encode sequences\n",
        "         seq = tokenizer.texts_to_sequences(lines)\n",
        "         # pad sequences with 0 values\n",
        "         seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "         return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRuiIZHCXVgm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data into train and test set\n",
        "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_XrSE_XXbL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare training data\n",
        "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "\n",
        "# prepare validation data\n",
        "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgtxBZT0Xe7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build NMT model\n",
        "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
        "      model = Sequential()\n",
        "      model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "      model.add(LSTM(units))\n",
        "      model.add(RepeatVector(out_timesteps))\n",
        "      model.add(LSTM(units, return_sequences=True))\n",
        "      model.add(Dense(out_vocab, activation='softmax'))\n",
        "      return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLjQp92oXj7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "96feda54-2aa2-44e8-c275-a3c9b66eac87"
      },
      "source": [
        "# model compilation\n",
        "model = define_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYDL4aG5XoMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a94b44c0-f819-4d20-acf9-2a625cc55b0b"
      },
      "source": [
        "rms = optimizers.RMSprop(lr=0.001)\n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSkmCn7DXsY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "85430713-067d-404c-8612-ffe609d3a00c"
      },
      "source": [
        "filename = '/content/drive/My Drive/nlp/german_latest.h5'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# train model\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
        "                    epochs=15, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \n",
        "                    verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 130927 samples, validate on 32732 samples\n",
            "Epoch 1/15\n",
            "130927/130927 [==============================] - 1377s 11ms/step - loss: 4.9455 - val_loss: 4.6423\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.64235, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 2/15\n",
            "130927/130927 [==============================] - 1382s 11ms/step - loss: 4.3534 - val_loss: 4.1159\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.64235 to 4.11591, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 3/15\n",
            "130927/130927 [==============================] - 1369s 10ms/step - loss: 3.9002 - val_loss: 3.7282\n",
            "\n",
            "Epoch 00003: val_loss improved from 4.11591 to 3.72817, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 4/15\n",
            "130927/130927 [==============================] - 1372s 10ms/step - loss: 3.5005 - val_loss: 3.3872\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.72817 to 3.38717, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 5/15\n",
            "130927/130927 [==============================] - 1392s 11ms/step - loss: 3.1407 - val_loss: 3.1243\n",
            "\n",
            "Epoch 00005: val_loss improved from 3.38717 to 3.12427, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 6/15\n",
            "130927/130927 [==============================] - 1387s 11ms/step - loss: 2.8408 - val_loss: 2.8934\n",
            "\n",
            "Epoch 00006: val_loss improved from 3.12427 to 2.89337, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 7/15\n",
            "130927/130927 [==============================] - 1392s 11ms/step - loss: 2.5924 - val_loss: 2.7479\n",
            "\n",
            "Epoch 00007: val_loss improved from 2.89337 to 2.74793, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 8/15\n",
            "130927/130927 [==============================] - 1384s 11ms/step - loss: 2.3824 - val_loss: 2.6145\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.74793 to 2.61449, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 9/15\n",
            "130927/130927 [==============================] - 1394s 11ms/step - loss: 2.2017 - val_loss: 2.5521\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.61449 to 2.55206, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 10/15\n",
            "130927/130927 [==============================] - 1398s 11ms/step - loss: 2.0420 - val_loss: 2.4714\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.55206 to 2.47144, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 11/15\n",
            "130927/130927 [==============================] - 1406s 11ms/step - loss: 1.9009 - val_loss: 2.4174\n",
            "\n",
            "Epoch 00011: val_loss improved from 2.47144 to 2.41741, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 12/15\n",
            "130927/130927 [==============================] - 1409s 11ms/step - loss: 1.7718 - val_loss: 2.3841\n",
            "\n",
            "Epoch 00012: val_loss improved from 2.41741 to 2.38414, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 13/15\n",
            "130927/130927 [==============================] - 1404s 11ms/step - loss: 1.6542 - val_loss: 2.3652\n",
            "\n",
            "Epoch 00013: val_loss improved from 2.38414 to 2.36522, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 14/15\n",
            "130927/130927 [==============================] - 1404s 11ms/step - loss: 1.5461 - val_loss: 2.3479\n",
            "\n",
            "Epoch 00014: val_loss improved from 2.36522 to 2.34793, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 15/15\n",
            "130560/130927 [============================>.] - ETA: 3s - loss: 1.4420WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 130927 samples, validate on 32732 samples\n",
            "Epoch 1/15\n",
            "130927/130927 [==============================] - 1377s 11ms/step - loss: 4.9455 - val_loss: 4.6423\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.64235, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 2/15\n",
            "130927/130927 [==============================] - 1382s 11ms/step - loss: 4.3534 - val_loss: 4.1159\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.64235 to 4.11591, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 3/15\n",
            "130927/130927 [==============================] - 1369s 10ms/step - loss: 3.9002 - val_loss: 3.7282\n",
            "\n",
            "Epoch 00003: val_loss improved from 4.11591 to 3.72817, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 4/15\n",
            "130927/130927 [==============================] - 1372s 10ms/step - loss: 3.5005 - val_loss: 3.3872\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.72817 to 3.38717, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 5/15\n",
            "130927/130927 [==============================] - 1392s 11ms/step - loss: 3.1407 - val_loss: 3.1243\n",
            "\n",
            "Epoch 00005: val_loss improved from 3.38717 to 3.12427, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 6/15\n",
            "130927/130927 [==============================] - 1387s 11ms/step - loss: 2.8408 - val_loss: 2.8934\n",
            "\n",
            "Epoch 00006: val_loss improved from 3.12427 to 2.89337, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 7/15\n",
            "130927/130927 [==============================] - 1392s 11ms/step - loss: 2.5924 - val_loss: 2.7479\n",
            "\n",
            "Epoch 00007: val_loss improved from 2.89337 to 2.74793, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 8/15\n",
            "130927/130927 [==============================] - 1384s 11ms/step - loss: 2.3824 - val_loss: 2.6145\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.74793 to 2.61449, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 9/15\n",
            "130927/130927 [==============================] - 1394s 11ms/step - loss: 2.2017 - val_loss: 2.5521\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.61449 to 2.55206, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 10/15\n",
            "130927/130927 [==============================] - 1398s 11ms/step - loss: 2.0420 - val_loss: 2.4714\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.55206 to 2.47144, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 11/15\n",
            "130927/130927 [==============================] - 1406s 11ms/step - loss: 1.9009 - val_loss: 2.4174\n",
            "\n",
            "Epoch 00011: val_loss improved from 2.47144 to 2.41741, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 12/15\n",
            "130927/130927 [==============================] - 1409s 11ms/step - loss: 1.7718 - val_loss: 2.3841\n",
            "\n",
            "Epoch 00012: val_loss improved from 2.41741 to 2.38414, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 13/15\n",
            "130927/130927 [==============================] - 1404s 11ms/step - loss: 1.6542 - val_loss: 2.3652\n",
            "\n",
            "Epoch 00013: val_loss improved from 2.38414 to 2.36522, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 14/15\n",
            "130927/130927 [==============================] - 1404s 11ms/step - loss: 1.5461 - val_loss: 2.3479\n",
            "\n",
            "Epoch 00014: val_loss improved from 2.36522 to 2.34793, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "Epoch 15/15\n",
            "130927/130927 [==============================] - 1406s 11ms/step - loss: 1.4425 - val_loss: 2.3459\n",
            "130927/130927 [==============================] - 1406s 11ms/step - loss: 1.4425 - val_loss: 2.3459\n",
            "\n",
            "Epoch 00015: val_loss improved from 2.34793 to 2.34588, saving model to /content/drive/My Drive/nlp/german_latest.h5\n",
            "\n",
            "Epoch 00015: val_loss improved from 2.34793 to 2.34588, saving model to /content/drive/My Drive/nlp/german_latest.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDDGkuJcYTrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViXogcDyYXzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('/content/drive/My Drive/nlp/german_latest.h5')\n",
        "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDPmyOOgYfzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word(n, tokenizer):\n",
        "      for word, index in tokenizer.word_index.items():\n",
        "          if index == n:\n",
        "              return word\n",
        "      return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxJ4UpenYlL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_text = []\n",
        "for i in preds:\n",
        "       temp = []\n",
        "       for j in range(len(i)):\n",
        "            t = get_word(i[j], eng_tokenizer)\n",
        "            if j > 0:\n",
        "                if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "                     temp.append('')\n",
        "                else:\n",
        "                     temp.append(t)\n",
        "            else:\n",
        "                   if(t == None):\n",
        "                          temp.append('')\n",
        "                   else:\n",
        "                          temp.append(t) \n",
        "\n",
        "       preds_text.append(' '.join(temp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tknLgOYvYrJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfYgK2LtY63n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cbad8736-b582-4759-c3cb-6bb35f2a1e16"
      },
      "source": [
        "# print 15 rows randomly\n",
        "pred_df.sample(15)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18750</th>\n",
              "      <td>you cant have your own way in everything</td>\n",
              "      <td>you cant have your  way  everything</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24592</th>\n",
              "      <td>there are a lot of english books in this library</td>\n",
              "      <td>have a many books  in the library</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22681</th>\n",
              "      <td>my father encouraged me to study the piano</td>\n",
              "      <td>my father me  to   study</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5370</th>\n",
              "      <td>tom is now a multimillionaire</td>\n",
              "      <td>tom is a now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2128</th>\n",
              "      <td>i bought a red sweater at that shop</td>\n",
              "      <td>bought   white sweater in this</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16074</th>\n",
              "      <td>you are a workaholic</td>\n",
              "      <td>youre a workaholic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2292</th>\n",
              "      <td>i might be able to help you</td>\n",
              "      <td>i may can help you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23563</th>\n",
              "      <td>you should work in the interests of humanity</td>\n",
              "      <td>you should be interested in  class you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10931</th>\n",
              "      <td>i think you like tom</td>\n",
              "      <td>i think you like tom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35231</th>\n",
              "      <td>you place me in a difficult position</td>\n",
              "      <td>you make me a  great</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27542</th>\n",
              "      <td>you reek of alcohol</td>\n",
              "      <td>you are a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40811</th>\n",
              "      <td>do you want him</td>\n",
              "      <td>do you want it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26079</th>\n",
              "      <td>tom always washes his hands before eating anything</td>\n",
              "      <td>tom always eat before   he eating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39007</th>\n",
              "      <td>his picture was in the newspaper</td>\n",
              "      <td>the book was on the paper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19824</th>\n",
              "      <td>do you think itll be easy to find a job in boston</td>\n",
              "      <td>its is in   to in place</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   actual                               predicted\n",
              "18750            you cant have your own way in everything     you cant have your  way  everything\n",
              "24592    there are a lot of english books in this library       have a many books  in the library\n",
              "22681          my father encouraged me to study the piano                my father me  to   study\n",
              "5370                        tom is now a multimillionaire                        tom is a now    \n",
              "2128                  i bought a red sweater at that shop         bought   white sweater in this \n",
              "16074                                you are a workaholic                 youre a workaholic     \n",
              "2292                          i might be able to help you                   i may can help you   \n",
              "23563        you should work in the interests of humanity  you should be interested in  class you\n",
              "10931                                i think you like tom                 i think you like tom   \n",
              "35231                you place me in a difficult position                  you make me a  great  \n",
              "27542                                 you reek of alcohol                          you are a     \n",
              "40811                                     do you want him                      do you want it    \n",
              "26079  tom always washes his hands before eating anything       tom always eat before   he eating\n",
              "39007                    his picture was in the newspaper             the book was on the paper  \n",
              "19824   do you think itll be easy to find a job in boston                 its is in   to in place"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18750</th>\n",
              "      <td>you cant have your own way in everything</td>\n",
              "      <td>you cant have your  way  everything</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24592</th>\n",
              "      <td>there are a lot of english books in this library</td>\n",
              "      <td>have a many books  in the library</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22681</th>\n",
              "      <td>my father encouraged me to study the piano</td>\n",
              "      <td>my father me  to   study</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5370</th>\n",
              "      <td>tom is now a multimillionaire</td>\n",
              "      <td>tom is a now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2128</th>\n",
              "      <td>i bought a red sweater at that shop</td>\n",
              "      <td>bought   white sweater in this</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16074</th>\n",
              "      <td>you are a workaholic</td>\n",
              "      <td>youre a workaholic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2292</th>\n",
              "      <td>i might be able to help you</td>\n",
              "      <td>i may can help you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23563</th>\n",
              "      <td>you should work in the interests of humanity</td>\n",
              "      <td>you should be interested in  class you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10931</th>\n",
              "      <td>i think you like tom</td>\n",
              "      <td>i think you like tom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35231</th>\n",
              "      <td>you place me in a difficult position</td>\n",
              "      <td>you make me a  great</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27542</th>\n",
              "      <td>you reek of alcohol</td>\n",
              "      <td>you are a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40811</th>\n",
              "      <td>do you want him</td>\n",
              "      <td>do you want it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26079</th>\n",
              "      <td>tom always washes his hands before eating anything</td>\n",
              "      <td>tom always eat before   he eating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39007</th>\n",
              "      <td>his picture was in the newspaper</td>\n",
              "      <td>the book was on the paper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19824</th>\n",
              "      <td>do you think itll be easy to find a job in boston</td>\n",
              "      <td>its is in   to in place</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   actual                               predicted\n",
              "18750            you cant have your own way in everything     you cant have your  way  everything\n",
              "24592    there are a lot of english books in this library       have a many books  in the library\n",
              "22681          my father encouraged me to study the piano                my father me  to   study\n",
              "5370                        tom is now a multimillionaire                        tom is a now    \n",
              "2128                  i bought a red sweater at that shop         bought   white sweater in this \n",
              "16074                                you are a workaholic                 youre a workaholic     \n",
              "2292                          i might be able to help you                   i may can help you   \n",
              "23563        you should work in the interests of humanity  you should be interested in  class you\n",
              "10931                                i think you like tom                 i think you like tom   \n",
              "35231                you place me in a difficult position                  you make me a  great  \n",
              "27542                                 you reek of alcohol                          you are a     \n",
              "40811                                     do you want him                      do you want it    \n",
              "26079  tom always washes his hands before eating anything       tom always eat before   he eating\n",
              "39007                    his picture was in the newspaper             the book was on the paper  \n",
              "19824   do you think itll be easy to find a job in boston                 its is in   to in place"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhmwMsxGraAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}